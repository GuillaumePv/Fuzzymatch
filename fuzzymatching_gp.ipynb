{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.1 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Fuzzy matching algorithm\n",
    "\n",
    "* https://towardsdatascience.com/fuzzy-matching-at-scale-84f2bfd0c536\n",
    "* https://bergvca.github.io/2017/10/14/super-fast-string-matching.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting sparse_dot_topn\n",
      "  Downloading sparse_dot_topn-0.2.9.tar.gz (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 90 kB/s \n",
      "\u001b[?25hRequirement already satisfied: setuptools>=18.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from sparse_dot_topn) (45.2.0)\n",
      "Collecting cython>=0.29.15\n",
      "  Using cached Cython-0.29.23-cp38-cp38-macosx_10_9_x86_64.whl (1.9 MB)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from sparse_dot_topn) (1.19.5)\n",
      "Requirement already satisfied: scipy>=1.2.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from sparse_dot_topn) (1.4.1)\n",
      "Building wheels for collected packages: sparse-dot-topn\n",
      "  Building wheel for sparse-dot-topn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sparse-dot-topn: filename=sparse_dot_topn-0.2.9-cp38-cp38-macosx_10_9_x86_64.whl size=57465 sha256=ad02a2270628e171f259064d060821cebff41082d682130709ed6d38f8f184d9\n",
      "  Stored in directory: /Users/guillaume/Library/Caches/pip/wheels/4a/64/25/2e1cedbf7513fecda8d396a0431f3a1e217f45f1ab565e8ce8\n",
      "Successfully built sparse-dot-topn\n",
      "Installing collected packages: cython, sparse-dot-topn\n",
      "Successfully installed cython-0.29.23 sparse-dot-topn-0.2.9\n"
     ]
    }
   ],
   "source": [
    "!pip install sparse_dot_topn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import sparse_dot_topn.sparse_dot_topn as ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting ftfy\n",
      "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
      "\u001b[K     |████████████████████████████████| 64 kB 185 kB/s \n",
      "\u001b[?25hRequirement already satisfied: wcwidth in /Users/guillaume/Library/Python/3.8/lib/python/site-packages (from ftfy) (0.2.5)\n",
      "Building wheels for collected packages: ftfy\n",
      "  Building wheel for ftfy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41913 sha256=b353a03643f2d76350c407a8c800a7ce39e4898da0a5a4e0873820b632d3e1ec\n",
      "  Stored in directory: /Users/guillaume/Library/Caches/pip/wheels/7f/40/63/4bf603cec3ecc4a26985405834cb47eb8368bfa59e15dde046\n",
      "Successfully built ftfy\n",
      "Installing collected packages: ftfy\n",
      "Successfully installed ftfy-6.0.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle #optional - for saving outputs\n",
    "import re\n",
    "from tqdm import tqdm # used for progress bars (optional)\n",
    "!pip install ftfy #  text cleaning for decode issues..\n",
    "import time\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "from ftfy import fix_text\n",
    "#transforms company names with assumptions taken from: http://www.legislation.gov.uk/uksi/2015/17/regulation/2/made\n",
    "def ngrams(string, n=3):\n",
    "    \"\"\"Takes an input string, cleans it and converts to ngrams. \n",
    "    This script is focussed on cleaning UK company names but can be made generic by removing lines below\"\"\"\n",
    "    string = str(string)\n",
    "    string = string.lower() # lower case\n",
    "    string = fix_text(string) # fix text\n",
    "    string = string.split('t/a')[0] # split on 'trading as' and return first name only\n",
    "    #string = string.split('trading as')[0] # split on 'trading as' and return first name only\n",
    "    string = string.encode(\"ascii\", errors=\"ignore\").decode() #remove non ascii chars\n",
    "    chars_to_remove = [\")\",\"(\",\".\",\"|\",\"[\",\"]\",\"{\",\"}\",\"'\",\"-\"]\n",
    "    rx = '[' + re.escape(''.join(chars_to_remove)) + ']' #remove punc, brackets etc...\n",
    "    string = re.sub(rx, '', string)\n",
    "    string = string.replace('&', 'and')\n",
    "    #string = string.replace('limited', 'ltd')\n",
    "    #string = string.replace('public limited company', 'plc')\n",
    "    #string = string.replace('united kingdom', 'uk')\n",
    "    #string = string.replace('community interest company', 'cic')\n",
    "    string = string.title() # normalise case - capital at start of each word\n",
    "    string = re.sub(' +',' ',string).strip() # get rid of multiple spaces and replace with a single\n",
    "    string = ' '+ string +' ' # pad names for ngrams...\n",
    "    ngrams = zip(*[string[i:] for i in range(n)])\n",
    "    return [''.join(ngram) for ngram in ngrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          id            author\n",
       "1          1     Charles Sykes\n",
       "2          2        Yogi Berra\n",
       "3          3  Michael Crichton\n",
       "4          4             Hegar\n",
       "5          5     Ken Bensinger\n",
       "...      ...               ...\n",
       "96677  96677            Gavell\n",
       "96678  96678  Adriana Trigiani\n",
       "96679  96679       Kien Nguyen\n",
       "96680  96680        Kyle Mills\n",
       "96681  96681  Elizabeth Redern\n",
       "\n",
       "[96681 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>author</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Charles Sykes</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Yogi Berra</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Michael Crichton</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Hegar</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>Ken Bensinger</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>96677</th>\n      <td>96677</td>\n      <td>Gavell</td>\n    </tr>\n    <tr>\n      <th>96678</th>\n      <td>96678</td>\n      <td>Adriana Trigiani</td>\n    </tr>\n    <tr>\n      <th>96679</th>\n      <td>96679</td>\n      <td>Kien Nguyen</td>\n    </tr>\n    <tr>\n      <th>96680</th>\n      <td>96680</td>\n      <td>Kyle Mills</td>\n    </tr>\n    <tr>\n      <th>96681</th>\n      <td>96681</td>\n      <td>Elizabeth Redern</td>\n    </tr>\n  </tbody>\n</table>\n<p>96681 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "#output data\n",
    "#df = pd.read_csv('./data/training_data.csv',error_bad_lines=False,encoding='cp1252',sep=\"\\t\")\n",
    "df_x = pd.read_csv('./data/input_x.csv',error_bad_lines=False,encoding='utf-8',sep=\"\\t\").iloc[1:,:]\n",
    "df_y = pd.read_csv('./data/input_y.csv',error_bad_lines=False,encoding='ISO 8859-1',sep=\"\\t\",header=None)\n",
    "df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<50745x11912 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 672201 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "artist_name = list(df_x['author'].dropna().unique())\n",
    "vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams)\n",
    "tf_idf_matrix = vectorizer.fit_transform(artist_name)\n",
    "tf_idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy_artist = list(df_y[1].unique())\n",
    "messy_tf_idf_matrix = vectorizer.transform(messy_artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting nmslib\n",
      "  Downloading nmslib-2.1.1-cp38-cp38-macosx_10_15_x86_64.whl (935 kB)\n",
      "\u001b[K     |████████████████████████████████| 935 kB 439 kB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.10.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from nmslib) (1.19.5)\n",
      "Collecting psutil\n",
      "  Using cached psutil-5.8.0-cp38-cp38-macosx_10_9_x86_64.whl (236 kB)\n",
      "Collecting pybind11<2.6.2\n",
      "  Downloading pybind11-2.6.1-py2.py3-none-any.whl (188 kB)\n",
      "\u001b[K     |████████████████████████████████| 188 kB 313 kB/s \n",
      "\u001b[?25hInstalling collected packages: pybind11, psutil, nmslib\n",
      "Successfully installed nmslib-2.1.1 psutil-5.8.0 pybind11-2.6.1\n",
      "Indexing time = 0.048763\n"
     ]
    }
   ],
   "source": [
    "!pip install nmslib\n",
    "import nmslib\n",
    "from scipy.sparse import csr_matrix # may not be required \n",
    "from scipy.sparse import rand # may not be required\n",
    "\n",
    "\n",
    "# create a random matrix to index\n",
    "data_matrix = tf_idf_matrix#[0:1000000]\n",
    "\n",
    "# Set index parameters\n",
    "# These are the most important ones\n",
    "M = 80\n",
    "efC = 1000\n",
    "\n",
    "num_threads = 4 # adjust for the number of threads\n",
    "# Intitialize the library, specify the space, the type of the vector and add data points \n",
    "index = nmslib.init(method='simple_invindx', space='negdotprod_sparse_fast', data_type=nmslib.DataType.SPARSE_VECTOR) \n",
    "\n",
    "index.addDataPointBatch(data_matrix)\n",
    "# Create an index\n",
    "start = time.time()\n",
    "index.createIndex() \n",
    "end = time.time() \n",
    "print('Indexing time = %f' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "kNN time total=2.185614 (sec), per query=0.000301 (sec), per query adjusted for thread number=0.001204 (sec)\n"
     ]
    }
   ],
   "source": [
    "# Number of neighbors \n",
    "num_threads = 4\n",
    "K=1\n",
    "query_matrix = messy_tf_idf_matrix\n",
    "start = time.time() \n",
    "query_qty = query_matrix.shape[0]\n",
    "nbrs = index.knnQueryBatch(query_matrix, k = K, num_threads = num_threads)\n",
    "end = time.time() \n",
    "print('kNN time total=%f (sec), per query=%f (sec), per query adjusted for thread number=%f (sec)' % \n",
    "      (end-start, float(end-start)/query_qty, num_threads*float(end-start)/query_qty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            origional_name        matched_name      conf\n",
       "0             Allen Eskens        Allen Eskens -1.000000\n",
       "1               C.D. Reiss           C.D. Rose -0.668106\n",
       "2          Catherine Gayle           Catherine -0.704948\n",
       "3         Daniel J. Siegel    Daniel J. Siegel -1.000000\n",
       "4          Debbie Macomber     Debbie Macomber -1.000000\n",
       "...                    ...                 ...       ...\n",
       "7254             Zondervan           Zondervan -1.000000\n",
       "7255    Zora Neale Hurston  Zora Neale Hurston -1.000000\n",
       "7256  edited by Brian Kram          Brian Kreb -0.326442\n",
       "7257  âConsumer Reportsâ     Bleacher Report -0.472838\n",
       "7258    âVibeâ editors              Editor -0.743496\n",
       "\n",
       "[7259 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>origional_name</th>\n      <th>matched_name</th>\n      <th>conf</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Allen Eskens</td>\n      <td>Allen Eskens</td>\n      <td>-1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>C.D. Reiss</td>\n      <td>C.D. Rose</td>\n      <td>-0.668106</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Catherine Gayle</td>\n      <td>Catherine</td>\n      <td>-0.704948</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Daniel J. Siegel</td>\n      <td>Daniel J. Siegel</td>\n      <td>-1.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Debbie Macomber</td>\n      <td>Debbie Macomber</td>\n      <td>-1.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7254</th>\n      <td>Zondervan</td>\n      <td>Zondervan</td>\n      <td>-1.000000</td>\n    </tr>\n    <tr>\n      <th>7255</th>\n      <td>Zora Neale Hurston</td>\n      <td>Zora Neale Hurston</td>\n      <td>-1.000000</td>\n    </tr>\n    <tr>\n      <th>7256</th>\n      <td>edited by Brian Kram</td>\n      <td>Brian Kreb</td>\n      <td>-0.326442</td>\n    </tr>\n    <tr>\n      <th>7257</th>\n      <td>âConsumer Reportsâ</td>\n      <td>Bleacher Report</td>\n      <td>-0.472838</td>\n    </tr>\n    <tr>\n      <th>7258</th>\n      <td>âVibeâ editors</td>\n      <td>Editor</td>\n      <td>-0.743496</td>\n    </tr>\n  </tbody>\n</table>\n<p>7259 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "mts =[]\n",
    "for i in range(len(nbrs)):\n",
    "  origional_nm = messy_artist[i]\n",
    "  try:\n",
    "    matched_nm   = artist_name[nbrs[i][0][0]]\n",
    "    conf         = nbrs[i][1][0]\n",
    "  except:\n",
    "    matched_nm   = \"no match found\"\n",
    "    conf         = None\n",
    "  mts.append([origional_nm,matched_nm,conf])\n",
    "\n",
    "mts = pd.DataFrame(mts,columns=['origional_name','matched_name','conf'])\n",
    "#results = df_CF.merge(mts,left_on='buyer',right_on='origional_name')\n",
    "mts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: sparse_dot_topn in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (0.2.9)\nRequirement already satisfied: scipy>=1.2.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from sparse_dot_topn) (1.4.1)\nRequirement already satisfied: cython>=0.29.15 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from sparse_dot_topn) (0.29.23)\nRequirement already satisfied: setuptools>=18.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from sparse_dot_topn) (45.2.0)\nRequirement already satisfied: numpy>=1.16.6 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from sparse_dot_topn) (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "!pip install sparse_dot_topn #uncomment to install\n",
    "import sparse_dot_topn.sparse_dot_topn as ct\n",
    "\n",
    "\n",
    "def awesome_cossim_top(A, B, ntop, lower_bound=0):\n",
    "    # force A and B as a CSR matrix.\n",
    "    # If they have already been CSR, there is no overhead\n",
    "    A = A.tocsr()\n",
    "    B = B.tocsr()\n",
    "    M, _ = A.shape\n",
    "    _, N = B.shape\n",
    " \n",
    "    idx_dtype = np.int32\n",
    " \n",
    "    nnz_max = M*ntop\n",
    " \n",
    "    indptr = np.zeros(M+1, dtype=idx_dtype)\n",
    "    indices = np.zeros(nnz_max, dtype=idx_dtype)\n",
    "    data = np.zeros(nnz_max, dtype=A.dtype)\n",
    "\n",
    "    ct.sparse_dot_topn(\n",
    "        M, N, np.asarray(A.indptr, dtype=idx_dtype),\n",
    "        np.asarray(A.indices, dtype=idx_dtype),\n",
    "        A.data,\n",
    "        np.asarray(B.indptr, dtype=idx_dtype),\n",
    "        np.asarray(B.indices, dtype=idx_dtype),\n",
    "        B.data,\n",
    "        ntop,\n",
    "        lower_bound,\n",
    "        indptr, indices, data)\n",
    "\n",
    "    return csr_matrix((data,indices,indptr),shape=(M,N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "artist_names = df_y[1].dropna().unique()\n",
    "vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams)\n",
    "tf_idf_matrix = vectorizer.fit_transform(artist_names)\n",
    "\n",
    "matches = awesome_cossim_top(tf_idf_matrix, tf_idf_matrix.transpose(), 10, 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matches_df(sparse_matrix, name_vector, top=100):\n",
    "    non_zeros = sparse_matrix.nonzero()\n",
    "    \n",
    "    sparserows = non_zeros[0]\n",
    "    sparsecols = non_zeros[1]\n",
    "    \n",
    "    if top:\n",
    "        nr_matches = top\n",
    "    else:\n",
    "        nr_matches = sparsecols.size\n",
    "    \n",
    "    left_side = np.empty([nr_matches], dtype=object)\n",
    "    right_side = np.empty([nr_matches], dtype=object)\n",
    "    similairity = np.zeros(nr_matches)\n",
    "    \n",
    "    for index in range(0, nr_matches):\n",
    "        left_side[index] = name_vector[sparserows[index]]\n",
    "        right_side[index] = name_vector[sparsecols[index]]\n",
    "        similairity[index] = sparse_matrix.data[index]\n",
    "    \n",
    "    return pd.DataFrame({'left_side': left_side,\n",
    "                          'right_side': right_side,\n",
    "                           'similairity': similairity})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                          left_side                      right_side  \\\n",
       "256                  Christie Craig                    David Clarke   \n",
       "258                    David Clarke                  Christie Craig   \n",
       "875                Elizabeth Swados                  Lecia Cornwall   \n",
       "870                  Lecia Cornwall                Elizabeth Swados   \n",
       "657                  Maria Goldverg                   Andrea Schulz   \n",
       "14                     Faith Hunter                      Rod Duncan   \n",
       "505                     Ally Condie                       Mussolini   \n",
       "507                       Mussolini                     Ally Condie   \n",
       "181                  Chloe Caldwell  Brain Fitness Lab Lisa Mosconi   \n",
       "183  Brain Fitness Lab Lisa Mosconi                  Chloe Caldwell   \n",
       "481                  Carolyn Marino                        Amy Plum   \n",
       "452                   Monica Murphy                     Pura Belpre   \n",
       "455                     Pura Belpre                   Monica Murphy   \n",
       "561                  Kristin Hannah               Jonathan Alderfer   \n",
       "556               Jonathan Alderfer                  Kristin Hannah   \n",
       "15                     Faith Hunter              Matthew De Abaitua   \n",
       "713                 Rebecca Grabill               Roseanne Montillo   \n",
       "715               Roseanne Montillo                 Rebecca Grabill   \n",
       "148                          Ponlop                     Ann Bracken   \n",
       "140                     Ann Bracken                          Ponlop   \n",
       "\n",
       "     similairity  \n",
       "256     0.937906  \n",
       "258     0.937906  \n",
       "875     0.927152  \n",
       "870     0.927152  \n",
       "657     0.920448  \n",
       "14      0.911747  \n",
       "505     0.910818  \n",
       "507     0.910818  \n",
       "181     0.905992  \n",
       "183     0.905992  \n",
       "481     0.905885  \n",
       "452     0.887648  \n",
       "455     0.887648  \n",
       "561     0.886312  \n",
       "556     0.886312  \n",
       "15      0.879666  \n",
       "713     0.879151  \n",
       "715     0.879151  \n",
       "148     0.877893  \n",
       "140     0.877893  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>left_side</th>\n      <th>right_side</th>\n      <th>similairity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>256</th>\n      <td>Christie Craig</td>\n      <td>David Clarke</td>\n      <td>0.937906</td>\n    </tr>\n    <tr>\n      <th>258</th>\n      <td>David Clarke</td>\n      <td>Christie Craig</td>\n      <td>0.937906</td>\n    </tr>\n    <tr>\n      <th>875</th>\n      <td>Elizabeth Swados</td>\n      <td>Lecia Cornwall</td>\n      <td>0.927152</td>\n    </tr>\n    <tr>\n      <th>870</th>\n      <td>Lecia Cornwall</td>\n      <td>Elizabeth Swados</td>\n      <td>0.927152</td>\n    </tr>\n    <tr>\n      <th>657</th>\n      <td>Maria Goldverg</td>\n      <td>Andrea Schulz</td>\n      <td>0.920448</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Faith Hunter</td>\n      <td>Rod Duncan</td>\n      <td>0.911747</td>\n    </tr>\n    <tr>\n      <th>505</th>\n      <td>Ally Condie</td>\n      <td>Mussolini</td>\n      <td>0.910818</td>\n    </tr>\n    <tr>\n      <th>507</th>\n      <td>Mussolini</td>\n      <td>Ally Condie</td>\n      <td>0.910818</td>\n    </tr>\n    <tr>\n      <th>181</th>\n      <td>Chloe Caldwell</td>\n      <td>Brain Fitness Lab Lisa Mosconi</td>\n      <td>0.905992</td>\n    </tr>\n    <tr>\n      <th>183</th>\n      <td>Brain Fitness Lab Lisa Mosconi</td>\n      <td>Chloe Caldwell</td>\n      <td>0.905992</td>\n    </tr>\n    <tr>\n      <th>481</th>\n      <td>Carolyn Marino</td>\n      <td>Amy Plum</td>\n      <td>0.905885</td>\n    </tr>\n    <tr>\n      <th>452</th>\n      <td>Monica Murphy</td>\n      <td>Pura Belpre</td>\n      <td>0.887648</td>\n    </tr>\n    <tr>\n      <th>455</th>\n      <td>Pura Belpre</td>\n      <td>Monica Murphy</td>\n      <td>0.887648</td>\n    </tr>\n    <tr>\n      <th>561</th>\n      <td>Kristin Hannah</td>\n      <td>Jonathan Alderfer</td>\n      <td>0.886312</td>\n    </tr>\n    <tr>\n      <th>556</th>\n      <td>Jonathan Alderfer</td>\n      <td>Kristin Hannah</td>\n      <td>0.886312</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Faith Hunter</td>\n      <td>Matthew De Abaitua</td>\n      <td>0.879666</td>\n    </tr>\n    <tr>\n      <th>713</th>\n      <td>Rebecca Grabill</td>\n      <td>Roseanne Montillo</td>\n      <td>0.879151</td>\n    </tr>\n    <tr>\n      <th>715</th>\n      <td>Roseanne Montillo</td>\n      <td>Rebecca Grabill</td>\n      <td>0.879151</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>Ponlop</td>\n      <td>Ann Bracken</td>\n      <td>0.877893</td>\n    </tr>\n    <tr>\n      <th>140</th>\n      <td>Ann Bracken</td>\n      <td>Ponlop</td>\n      <td>0.877893</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "\n",
    "matches_df = get_matches_df(matches, artist_name, top=1000)\n",
    "matches_df = matches_df[matches_df['similairity'] < 0.99999] # Remove all exact matches\n",
    "matches_df.sample(20)\n",
    "matches_df.sort_values(['similairity'], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Vectorizing the data - this could take a few minutes for large datasets...\n",
      "Vectorizing completed...\n",
      "getting nearest n...\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-16682e43350e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'getting nearest n...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetNearestN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_org\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"COMPLETED IN:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-16682e43350e>\u001b[0m in \u001b[0;36mgetNearestN\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetNearestN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0mqueryTFIDF_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnbrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueryTFIDF_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    638\u001b[0m                 \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m             chunked_results = list(pairwise_distances_chunked(\n\u001b[0m\u001b[1;32m    641\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m                 \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1602\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreduce_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m             \u001b[0mchunk_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1604\u001b[0;31m             \u001b[0mD_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1605\u001b[0m             \u001b[0m_check_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1606\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36m_kneighbors_reduce_func\u001b[0;34m(self, dist, start, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    516\u001b[0m         \"\"\"\n\u001b[1;32m    517\u001b[0m         \u001b[0msample_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m         \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneigh_ind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m# argpartition doesn't guarantee sorted order, so we sort again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margpartition\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margpartition\u001b[0;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m     \"\"\"\n\u001b[0;32m--> 832\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argpartition'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "artist_name_clean = df_x['author'].dropna().unique()\n",
    "\n",
    "print('Vectorizing the data - this could take a few minutes for large datasets...')\n",
    "vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams, lowercase=False)\n",
    "tfidf = vectorizer.fit_transform(artist_name_clean)\n",
    "print('Vectorizing completed...')\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "nbrs = NearestNeighbors(n_neighbors=1, n_jobs=-1).fit(tfidf)\n",
    "\n",
    "org_column = 'buyer' #column to match against in the messy data\n",
    "unique_artist = set(df_y['author'].values) # set used for increased performance\n",
    "\n",
    "\n",
    "###matching query:\n",
    "def getNearestN(query):\n",
    "  queryTFIDF_ = vectorizer.transform(query)\n",
    "  distances, indices = nbrs.kneighbors(queryTFIDF_)\n",
    "  return distances, indices\n",
    "\n",
    "import time\n",
    "t1 = time.time()\n",
    "print('getting nearest n...')\n",
    "distances, indices = getNearestN(unique_org)\n",
    "t = time.time()-t1\n",
    "print(\"COMPLETED IN:\", t)\n",
    "\n",
    "unique_org = list(unique_org) #need to convert back to a list\n",
    "print('finding matches...')\n",
    "matches = []\n",
    "for i,j in enumerate(indices):\n",
    "  temp = [round(distances[i][0],2), artist_name_clean.values[j][0][0],unique_artist[i]]\n",
    "  matches.append(temp)\n",
    "\n",
    "print('Building data frame...')  \n",
    "matches = pd.DataFrame(matches, columns=['Match confidence (lower is better)','Matched name','Origional name'])\n",
    "print('Done') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         0                author\n",
       "0        1          Allen Eskens\n",
       "1        2            C.D. Reiss\n",
       "2        3       Catherine Gayle\n",
       "3        4      Daniel J. Siegel\n",
       "4        5       Debbie Macomber\n",
       "...    ...                   ...\n",
       "8297  8298             Zondervan\n",
       "8298  8299    Zora Neale Hurston\n",
       "8299  8300  edited by Brian Kram\n",
       "8300  8301  âConsumer Reportsâ\n",
       "8301  8302    âVibeâ editors\n",
       "\n",
       "[8302 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>author</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Allen Eskens</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>C.D. Reiss</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Catherine Gayle</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Daniel J. Siegel</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Debbie Macomber</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8297</th>\n      <td>8298</td>\n      <td>Zondervan</td>\n    </tr>\n    <tr>\n      <th>8298</th>\n      <td>8299</td>\n      <td>Zora Neale Hurston</td>\n    </tr>\n    <tr>\n      <th>8299</th>\n      <td>8300</td>\n      <td>edited by Brian Kram</td>\n    </tr>\n    <tr>\n      <th>8300</th>\n      <td>8301</td>\n      <td>âConsumer Reportsâ</td>\n    </tr>\n    <tr>\n      <th>8301</th>\n      <td>8302</td>\n      <td>âVibeâ editors</td>\n    </tr>\n  </tbody>\n</table>\n<p>8302 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "df_y = df_y.rename(columns={1: \"author\"})\n",
    "df_y"
   ]
  },
  {
   "source": [
    "# Last try Guillaume\n",
    "* https://towardsdatascience.com/fuzzy-string-match-with-python-on-large-dataset-and-why-you-should-not-use-fuzzywuzzy-4ec9f0defcd"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import gc\n",
    "import timeit\n",
    "import sys\n",
    "from datetime import datetime as dt\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = pd.read_csv('./data/input_x.csv',error_bad_lines=False,encoding='utf-8',sep=\"\\t\").iloc[1:,:]\n",
    "df_y = pd.read_csv('./data/input_y.csv',error_bad_lines=False,encoding='ISO 8859-1',sep=\"\\t\",header=None)\n",
    "\n",
    "df_x = df_x.iloc[:1000,:]\n",
    "df_y = df_y.iloc[:1000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   0                 1\n",
       "0  1      Allen Eskens\n",
       "1  2        C.D. Reiss\n",
       "2  3   Catherine Gayle\n",
       "3  4  Daniel J. Siegel\n",
       "4  5   Debbie Macomber"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Allen Eskens</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>C.D. Reiss</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Catherine Gayle</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Daniel J. Siegel</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Debbie Macomber</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df_y.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_prepare(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: a clean string\n",
    "    \"\"\"\n",
    "    REPLACE_BY_SPACE_RE = re.compile('[\\n\\\"\\'/(){}\\[\\]\\|@,;#]')\n",
    "    text = re.sub(REPLACE_BY_SPACE_RE, ' ', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # delete stopwords from text\n",
    "    text = ' '.join([word for word in text.split()]) \n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "id         int64\n",
       "author    string\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df_x['author'] = df_x['author'].astype('string')\n",
    "df_x.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    0                                  1\n",
       "0   1                       Allen Eskens\n",
       "1   2                         C.D. Reiss\n",
       "2   3                    Catherine Gayle\n",
       "3   4                   Daniel J. Siegel\n",
       "4   5                    Debbie Macomber\n",
       "5   6                        Dick Morris\n",
       "6   7               Dolen Perkins-Valdez\n",
       "7   8               Donna Woolfolk Cross\n",
       "8   9  Douglas Preston and Lincoln Child\n",
       "9  10                       Emily Giffin"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Allen Eskens</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>C.D. Reiss</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Catherine Gayle</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Daniel J. Siegel</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Debbie Macomber</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>Dick Morris</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>Dolen Perkins-Valdez</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>Donna Woolfolk Cross</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>Douglas Preston and Lincoln Child</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>Emily Giffin</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df_y.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df_x.fillna(\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id            author            Author\n",
       "1   1     Charles Sykes     charles sykes\n",
       "2   2        Yogi Berra        yogi berra\n",
       "3   3  Michael Crichton  michael crichton\n",
       "4   4             Hegar             hegar\n",
       "5   5     Ken Bensinger     ken bensinger"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>author</th>\n      <th>Author</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Charles Sykes</td>\n      <td>charles sykes</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Yogi Berra</td>\n      <td>yogi berra</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Michael Crichton</td>\n      <td>michael crichton</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Hegar</td>\n      <td>hegar</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>Ken Bensinger</td>\n      <td>ken bensinger</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df_x['Author'] = df_x['author'].apply(lambda x: text_prepare(x))\n",
    "df_y['author'] = df_y[1].apply(lambda x: text_prepare(x))\n",
    "df_x.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform text to vectors with TF-IDF\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2), max_df=0.9, min_df=5, token_pattern='(\\S+)')\n",
    "tf_idf_matrix_x = tfidf_vectorizer.fit_transform(df_x['Author'])\n",
    "tf_idf_matrix_y = tfidf_vectorizer.fit_transform(df_y['author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: sparse_dot_topn in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (0.2.9)\n",
      "Requirement already satisfied: scipy>=1.2.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from sparse_dot_topn) (1.6.1)\n",
      "Requirement already satisfied: cython>=0.29.15 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from sparse_dot_topn) (0.29.23)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from sparse_dot_topn) (1.19.5)\n",
      "Requirement already satisfied: setuptools>=18.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from sparse_dot_topn) (45.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "finished in: 0.002249002456665039\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "!pip install sparse_dot_topn \n",
    "import sparse_dot_topn.sparse_dot_topn as ct\n",
    "\n",
    "def awesome_cossim_top(A, B, ntop, lower_bound=0):\n",
    "    # force A and B as a CSR matrix.\n",
    "    # If they have already been CSR, there is no overhead\n",
    "    A = A.tocsr()\n",
    "    B = B.tocsr()\n",
    "    M, _ = A.shape\n",
    "    _, N = B.shape\n",
    " \n",
    "    idx_dtype = np.int32\n",
    " \n",
    "    nnz_max = M*ntop\n",
    " \n",
    "    indptr = np.zeros(M+1, dtype=idx_dtype)\n",
    "    indices = np.zeros(nnz_max, dtype=idx_dtype)\n",
    "    data = np.zeros(nnz_max, dtype=A.dtype)\n",
    "    ct.sparse_dot_topn(\n",
    "            M, N, np.asarray(A.indptr, dtype=idx_dtype),\n",
    "            np.asarray(A.indices, dtype=idx_dtype),\n",
    "            A.data,\n",
    "            np.asarray(B.indptr, dtype=idx_dtype),\n",
    "            np.asarray(B.indices, dtype=idx_dtype),\n",
    "            B.data,\n",
    "            ntop,\n",
    "            lower_bound,\n",
    "            indptr, indices, data)\n",
    "    return csr_matrix((data,indices,indptr),shape=(M,N))\n",
    "\n",
    "\n",
    "import time\n",
    "t1 = time.time()\n",
    "\n",
    "# adjust lower bound: 0.8\n",
    "# keep top 10 similar results\n",
    "matches = awesome_cossim_top(tf_idf_matrix_x, tf_idf_matrix_y.transpose(), 10, 0.8)\n",
    "\n",
    "t = time.time()-t1\n",
    "print(\"finished in:\", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "0",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 0 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a74545ec7ea4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mmatches_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mmatches_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_matches_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Author'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;31m# Remove all exact matches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mmatches_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatches_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmatches_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'similairity_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.99999\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-a74545ec7ea4>\u001b[0m in \u001b[0;36mget_matches_df\u001b[0;34m(sparse_matrix, name_vector, top)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnr_matches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mleft_side\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msparserows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mright_side\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msparsecols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0msimilairity\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    351\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "def get_matches_df(sparse_matrix, name_vector, top=100):\n",
    "    non_zeros = sparse_matrix.nonzero()\n",
    "    \n",
    "    sparserows = non_zeros[0]\n",
    "    sparsecols = non_zeros[1]\n",
    "    \n",
    "    if top:\n",
    "        nr_matches = top\n",
    "    else:\n",
    "        nr_matches = sparsecols.size\n",
    "    \n",
    "    left_side = np.empty([nr_matches], dtype=object)\n",
    "    right_side = np.empty([nr_matches], dtype=object)\n",
    "    similairity = np.zeros(nr_matches)\n",
    "    \n",
    "    for index in range(0, nr_matches):\n",
    "        left_side[index] = name_vector[sparserows[index]]\n",
    "        right_side[index] = name_vector[sparsecols[index]]\n",
    "        similairity[index] = sparse_matrix.data[index]\n",
    "    \n",
    "    return pd.DataFrame({'TITLE': left_side,\n",
    "                          'SIMILAR_TITLE': right_side,\n",
    "                           'similairity_score': similairity})\n",
    "  \n",
    "  \n",
    "  \n",
    "matches_df = pd.DataFrame()\n",
    "matches_df = get_matches_df(matches, df_x['Author'], top=10000)\n",
    "# Remove all exact matches\n",
    "matches_df = matches_df[matches_df['similairity_score'] < 0.99999] \n",
    "matches_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                     TITLE            SIMILAR_TITLE  \\\n",
       "9708                         nebula awards     nebula awards awards   \n",
       "3658    arthur ellis unhanged arthur award       arthur ellis award   \n",
       "3657    arthur ellis unhanged arthur award       arthur ellis award   \n",
       "3656    arthur ellis unhanged arthur award       arthur ellis award   \n",
       "7281                            nino ricci         award nino ricci   \n",
       "1949                     charlotte zolotow  charlotte zolotow award   \n",
       "8574                         tom o donnell       sunshine o donnell   \n",
       "9507  wallace stegner fellow abigail ulman   wallace stegner fellow   \n",
       "9508  wallace stegner fellow abigail ulman   wallace stegner fellow   \n",
       "9509  wallace stegner fellow abigail ulman   wallace stegner fellow   \n",
       "4556                 arthur ellis unhanged       arthur ellis award   \n",
       "4555                 arthur ellis unhanged       arthur ellis award   \n",
       "4554                 arthur ellis unhanged       arthur ellis award   \n",
       "1179                       george o connor          varley o connor   \n",
       "1178                       george o connor          varley o connor   \n",
       "1177                       george o connor              tj o connor   \n",
       "1176                       george o connor         malachi o connor   \n",
       "4358                          david shafer                   shafer   \n",
       "7379                     chantele sedgwick            john sedgwick   \n",
       "448                               john all        against all grain   \n",
       "\n",
       "      similairity_score  \n",
       "9708           0.952539  \n",
       "3658           0.947048  \n",
       "3657           0.947048  \n",
       "3656           0.947048  \n",
       "7281           0.944778  \n",
       "1949           0.933302  \n",
       "8574           0.921246  \n",
       "9507           0.919925  \n",
       "9508           0.919925  \n",
       "9509           0.919925  \n",
       "4556           0.918731  \n",
       "4555           0.918731  \n",
       "4554           0.918731  \n",
       "1179           0.904928  \n",
       "1178           0.904928  \n",
       "1177           0.904928  \n",
       "1176           0.904928  \n",
       "4358           0.904260  \n",
       "7379           0.902625  \n",
       "448            0.902625  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TITLE</th>\n      <th>SIMILAR_TITLE</th>\n      <th>similairity_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9708</th>\n      <td>nebula awards</td>\n      <td>nebula awards awards</td>\n      <td>0.952539</td>\n    </tr>\n    <tr>\n      <th>3658</th>\n      <td>arthur ellis unhanged arthur award</td>\n      <td>arthur ellis award</td>\n      <td>0.947048</td>\n    </tr>\n    <tr>\n      <th>3657</th>\n      <td>arthur ellis unhanged arthur award</td>\n      <td>arthur ellis award</td>\n      <td>0.947048</td>\n    </tr>\n    <tr>\n      <th>3656</th>\n      <td>arthur ellis unhanged arthur award</td>\n      <td>arthur ellis award</td>\n      <td>0.947048</td>\n    </tr>\n    <tr>\n      <th>7281</th>\n      <td>nino ricci</td>\n      <td>award nino ricci</td>\n      <td>0.944778</td>\n    </tr>\n    <tr>\n      <th>1949</th>\n      <td>charlotte zolotow</td>\n      <td>charlotte zolotow award</td>\n      <td>0.933302</td>\n    </tr>\n    <tr>\n      <th>8574</th>\n      <td>tom o donnell</td>\n      <td>sunshine o donnell</td>\n      <td>0.921246</td>\n    </tr>\n    <tr>\n      <th>9507</th>\n      <td>wallace stegner fellow abigail ulman</td>\n      <td>wallace stegner fellow</td>\n      <td>0.919925</td>\n    </tr>\n    <tr>\n      <th>9508</th>\n      <td>wallace stegner fellow abigail ulman</td>\n      <td>wallace stegner fellow</td>\n      <td>0.919925</td>\n    </tr>\n    <tr>\n      <th>9509</th>\n      <td>wallace stegner fellow abigail ulman</td>\n      <td>wallace stegner fellow</td>\n      <td>0.919925</td>\n    </tr>\n    <tr>\n      <th>4556</th>\n      <td>arthur ellis unhanged</td>\n      <td>arthur ellis award</td>\n      <td>0.918731</td>\n    </tr>\n    <tr>\n      <th>4555</th>\n      <td>arthur ellis unhanged</td>\n      <td>arthur ellis award</td>\n      <td>0.918731</td>\n    </tr>\n    <tr>\n      <th>4554</th>\n      <td>arthur ellis unhanged</td>\n      <td>arthur ellis award</td>\n      <td>0.918731</td>\n    </tr>\n    <tr>\n      <th>1179</th>\n      <td>george o connor</td>\n      <td>varley o connor</td>\n      <td>0.904928</td>\n    </tr>\n    <tr>\n      <th>1178</th>\n      <td>george o connor</td>\n      <td>varley o connor</td>\n      <td>0.904928</td>\n    </tr>\n    <tr>\n      <th>1177</th>\n      <td>george o connor</td>\n      <td>tj o connor</td>\n      <td>0.904928</td>\n    </tr>\n    <tr>\n      <th>1176</th>\n      <td>george o connor</td>\n      <td>malachi o connor</td>\n      <td>0.904928</td>\n    </tr>\n    <tr>\n      <th>4358</th>\n      <td>david shafer</td>\n      <td>shafer</td>\n      <td>0.904260</td>\n    </tr>\n    <tr>\n      <th>7379</th>\n      <td>chantele sedgwick</td>\n      <td>john sedgwick</td>\n      <td>0.902625</td>\n    </tr>\n    <tr>\n      <th>448</th>\n      <td>john all</td>\n      <td>against all grain</td>\n      <td>0.902625</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "matches_df.sort_values([\"similairity_score\"], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}