{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.1 64-bit ('venv': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "interpreter": {
   "hash": "9d464054a1e6c09f5b57b761e8ac88ec16f7c207286a122e88e5fb45c6d95b86"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Fuzzy matching algorithm\n",
    "\n",
    "* https://towardsdatascience.com/fuzzy-matching-at-scale-84f2bfd0c536\n",
    "* https://bergvca.github.io/2017/10/14/super-fast-string-matching.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import sparse_dot_topn.sparse_dot_topn as ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting ftfy\n",
      "  Using cached https://files.pythonhosted.org/packages/af/da/d215a091986e5f01b80f5145cff6f22e2dc57c6b048aab2e882a07018473/ftfy-6.0.3.tar.gz\n",
      "Requirement already satisfied: wcwidth in ./venv/lib/python3.8/site-packages (from ftfy) (0.2.5)\n",
      "Building wheels for collected packages: ftfy\n",
      "  Building wheel for ftfy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ftfy: filename=ftfy-6.0.3-cp38-none-any.whl size=41933 sha256=5e5d5a0a2f8d5b4f9ca0ea3e3d662d59edbc37cef2112f439c433314e9c61758\n",
      "  Stored in directory: /Users/guillaume/Library/Caches/pip/wheels/99/2c/e6/109c8a28fef7a443f67ba58df21fe1d0067ac3322e75e6b0b7\n",
      "Successfully built ftfy\n",
      "Installing collected packages: ftfy\n",
      "Successfully installed ftfy-6.0.3\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 21.1.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle #optional - for saving outputs => best for large dataset\n",
    "import re\n",
    "from tqdm import tqdm # used for progress bars (optional)\n",
    "import time\n",
    "\n",
    "#ngram best result\n",
    "\n",
    "import re\n",
    "\n",
    "from ftfy import fix_text #  text cleaning for decode issues..\n",
    "#transforms company names with assumptions taken from: http://www.legislation.gov.uk/uksi/2015/17/regulation/2/made\n",
    "def ngrams(string, n=3):\n",
    "    \"\"\"Takes an input string, cleans it and converts to ngrams. \n",
    "    This script is focussed on cleaning UK company names but can be made generic by removing lines below\"\"\"\n",
    "    string = str(string)\n",
    "    string = string.lower() # lower case\n",
    "    string = fix_text(string) # fix text\n",
    "    string = string.split('t/a')[0] # split on 'trading as' and return first name only\n",
    "    #string = string.split('trading as')[0] # split on 'trading as' and return first name only\n",
    "    string = string.encode(\"ascii\", errors=\"ignore\").decode() #remove non ascii chars\n",
    "    chars_to_remove = [\")\",\"(\",\".\",\"|\",\"[\",\"]\",\"{\",\"}\",\"'\",\"-\"]\n",
    "    rx = '[' + re.escape(''.join(chars_to_remove)) + ']' #remove punc, brackets etc...\n",
    "    string = re.sub(rx, '', string)\n",
    "    string = string.replace('&', 'and')\n",
    "    #string = string.replace('limited', 'ltd')\n",
    "    #string = string.replace('public limited company', 'plc')\n",
    "    #string = string.replace('united kingdom', 'uk')\n",
    "    #string = string.replace('community interest company', 'cic')\n",
    "    string = string.title() # normalise case - capital at start of each word\n",
    "    string = re.sub(' +',' ',string).strip() # get rid of multiple spaces and replace with a single\n",
    "    string = ' '+ string +' ' # pad names for ngrams...\n",
    "    ngrams = zip(*[string[i:] for i in range(n)])\n",
    "    return [''.join(ngram) for ngram in ngrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output data\n",
    "#df = pd.read_csv('./data/training_data.csv',error_bad_lines=False,encoding='cp1252',sep=\"\\t\")\n",
    "df_x = pd.read_csv('./data/input_x.csv',error_bad_lines=False,encoding='utf-8',sep=\"\\t\").iloc[1:,:]\n",
    "df_y = pd.read_csv('./data/input_y.csv',error_bad_lines=False,encoding='ISO 8859-1',sep=\"\\t\",header=None)\n",
    "\n",
    "df_x['author'] = df_x['author'].astype('string')\n",
    "df_y['author'] = df_y[1].astype('string')\n",
    "\n",
    "del df_x['id']\n",
    "del df_y[0]\n",
    "del df_y[1]\n",
    "\n",
    "\n",
    "df_merge = df_x.append(df_y, ignore_index=True)\n",
    "df_merge = df_merge.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8302, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "df_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<50745x11912 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 672201 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "artist_name = list(df_x['author'].dropna().unique())\n",
    "vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams)\n",
    "tf_idf_matrix = vectorizer.fit_transform(artist_name)\n",
    "tf_idf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy_artist = list(df_y['author'].unique())\n",
    "messy_tf_idf_matrix = vectorizer.transform(messy_artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: nmslib in ./venv/lib/python3.8/site-packages (2.1.1)\n",
      "Requirement already satisfied: pybind11<2.6.2 in ./venv/lib/python3.8/site-packages (from nmslib) (2.6.1)\n",
      "Requirement already satisfied: psutil in ./venv/lib/python3.8/site-packages (from nmslib) (5.8.0)\n",
      "Requirement already satisfied: numpy>=1.10.0; python_version >= \"3.5\" in ./venv/lib/python3.8/site-packages (from nmslib) (1.20.3)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 21.1.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Indexing time = 0.061519\n"
     ]
    }
   ],
   "source": [
    "!pip install nmslib\n",
    "import nmslib\n",
    "from scipy.sparse import csr_matrix # may not be required \n",
    "from scipy.sparse import rand # may not be required\n",
    "\n",
    "\n",
    "# create a random matrix to index\n",
    "data_matrix = tf_idf_matrix#[0:1000000]\n",
    "\n",
    "# Set index parameters\n",
    "# These are the most important ones\n",
    "M = 80\n",
    "efC = 1000\n",
    "\n",
    "num_threads = 4 # adjust for the number of threads\n",
    "# Intitialize the library, specify the space, the type of the vector and add data points \n",
    "index = nmslib.init(method='simple_invindx', space='negdotprod_sparse_fast', data_type=nmslib.DataType.SPARSE_VECTOR) \n",
    "\n",
    "index.addDataPointBatch(data_matrix)\n",
    "# Create an index\n",
    "start = time.time()\n",
    "index.createIndex() \n",
    "end = time.time() \n",
    "print('Indexing time = %f' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "kNN time total=1.304228 (sec), per query=0.000180 (sec), per query adjusted for thread number=0.000719 (sec)\n"
     ]
    }
   ],
   "source": [
    "# Number of neighbors => use Knn\n",
    "num_threads = 4\n",
    "K=1\n",
    "query_matrix = messy_tf_idf_matrix\n",
    "start = time.time() \n",
    "query_qty = query_matrix.shape[0]\n",
    "nbrs = index.knnQueryBatch(query_matrix, k = K, num_threads = num_threads)\n",
    "end = time.time() \n",
    "print('kNN time total=%f (sec), per query=%f (sec), per query adjusted for thread number=%f (sec)' % \n",
    "      (end-start, float(end-start)/query_qty, num_threads*float(end-start)/query_qty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            origional_name        matched_name      conf\n",
       "0             Allen Eskens        Allen Eskens  1.000000\n",
       "1               C.D. Reiss           C.D. Rose  0.668106\n",
       "2          Catherine Gayle           Catherine  0.704948\n",
       "3         Daniel J. Siegel    Daniel J. Siegel  1.000000\n",
       "4          Debbie Macomber     Debbie Macomber  1.000000\n",
       "...                    ...                 ...       ...\n",
       "7254             Zondervan           Zondervan  1.000000\n",
       "7255    Zora Neale Hurston  Zora Neale Hurston  1.000000\n",
       "7256  edited by Brian Kram          Brian Kreb  0.326442\n",
       "7257  âConsumer Reportsâ     Bleacher Report  0.472838\n",
       "7258    âVibeâ editors              Editor  0.743496\n",
       "\n",
       "[7259 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>origional_name</th>\n      <th>matched_name</th>\n      <th>conf</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Allen Eskens</td>\n      <td>Allen Eskens</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>C.D. Reiss</td>\n      <td>C.D. Rose</td>\n      <td>0.668106</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Catherine Gayle</td>\n      <td>Catherine</td>\n      <td>0.704948</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Daniel J. Siegel</td>\n      <td>Daniel J. Siegel</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Debbie Macomber</td>\n      <td>Debbie Macomber</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7254</th>\n      <td>Zondervan</td>\n      <td>Zondervan</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>7255</th>\n      <td>Zora Neale Hurston</td>\n      <td>Zora Neale Hurston</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>7256</th>\n      <td>edited by Brian Kram</td>\n      <td>Brian Kreb</td>\n      <td>0.326442</td>\n    </tr>\n    <tr>\n      <th>7257</th>\n      <td>âConsumer Reportsâ</td>\n      <td>Bleacher Report</td>\n      <td>0.472838</td>\n    </tr>\n    <tr>\n      <th>7258</th>\n      <td>âVibeâ editors</td>\n      <td>Editor</td>\n      <td>0.743496</td>\n    </tr>\n  </tbody>\n</table>\n<p>7259 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "mts =[]\n",
    "for i in range(len(nbrs)):\n",
    "  origional_nm = messy_artist[i]\n",
    "  try:\n",
    "    matched_nm   = artist_name[nbrs[i][0][0]]\n",
    "    conf         = nbrs[i][1][0]\n",
    "  except:\n",
    "    matched_nm   = \"no match found\"\n",
    "    conf         = None\n",
    "  mts.append([origional_nm,matched_nm,conf])\n",
    "\n",
    "mts = pd.DataFrame(mts,columns=['origional_name','matched_name','conf'])\n",
    "#results = df_CF.merge(mts,left_on='buyer',right_on='origional_name')\n",
    "mts['conf'] = -mts['conf']\n",
    "mts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        origional_name      matched_name  conf\n",
       "1289         Ciji Ware         Ciji Ware   1.0\n",
       "1541        Dav Pilkey        Dav Pilkey   1.0\n",
       "2207    Eric Schlosser    Eric Schlosser   1.0\n",
       "364      Angela Liddon     Angela Liddon   1.0\n",
       "745    Bill OâReilly     Bill O'Reilly   1.0\n",
       "744      Bill OReilly     Bill O'Reilly   1.0\n",
       "741      Bill O'Reilly     Bill O'Reilly   1.0\n",
       "3122    Jefferson Bass    Jefferson Bass   1.0\n",
       "4329   Lindsay McKenna   Lindsay McKenna   1.0\n",
       "1008   Carole Mortimer   Carole Mortimer   1.0\n",
       "6940        Toni Blake        Toni Blake   1.0\n",
       "3648   Julia Donaldson   Julia Donaldson   1.0\n",
       "7141       Will Shortz       Will Shortz   1.0\n",
       "1157      Cherry Adair      Cherry Adair   1.0\n",
       "5300   Nouriel Roubini   Nouriel Roubini   1.0\n",
       "1018   Caroline Linden   Caroline Linden   1.0\n",
       "587   Barbara Coloroso  Barbara Coloroso   1.0\n",
       "2182   Emma McLaughlin   Emma McLaughlin   1.0\n",
       "6208    Sarah Pekkanen    Sarah Pekkanen   1.0\n",
       "5740     Renee Carlino     Renee Carlino   1.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>origional_name</th>\n      <th>matched_name</th>\n      <th>conf</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1289</th>\n      <td>Ciji Ware</td>\n      <td>Ciji Ware</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1541</th>\n      <td>Dav Pilkey</td>\n      <td>Dav Pilkey</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2207</th>\n      <td>Eric Schlosser</td>\n      <td>Eric Schlosser</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>364</th>\n      <td>Angela Liddon</td>\n      <td>Angela Liddon</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>745</th>\n      <td>Bill OâReilly</td>\n      <td>Bill O'Reilly</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>744</th>\n      <td>Bill OReilly</td>\n      <td>Bill O'Reilly</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>741</th>\n      <td>Bill O'Reilly</td>\n      <td>Bill O'Reilly</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3122</th>\n      <td>Jefferson Bass</td>\n      <td>Jefferson Bass</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4329</th>\n      <td>Lindsay McKenna</td>\n      <td>Lindsay McKenna</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1008</th>\n      <td>Carole Mortimer</td>\n      <td>Carole Mortimer</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>6940</th>\n      <td>Toni Blake</td>\n      <td>Toni Blake</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3648</th>\n      <td>Julia Donaldson</td>\n      <td>Julia Donaldson</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>7141</th>\n      <td>Will Shortz</td>\n      <td>Will Shortz</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1157</th>\n      <td>Cherry Adair</td>\n      <td>Cherry Adair</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5300</th>\n      <td>Nouriel Roubini</td>\n      <td>Nouriel Roubini</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1018</th>\n      <td>Caroline Linden</td>\n      <td>Caroline Linden</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>587</th>\n      <td>Barbara Coloroso</td>\n      <td>Barbara Coloroso</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2182</th>\n      <td>Emma McLaughlin</td>\n      <td>Emma McLaughlin</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>6208</th>\n      <td>Sarah Pekkanen</td>\n      <td>Sarah Pekkanen</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5740</th>\n      <td>Renee Carlino</td>\n      <td>Renee Carlino</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "mts.sort_values([\"conf\"], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: sparse_dot_topn in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (0.2.9)\nRequirement already satisfied: scipy>=1.2.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from sparse_dot_topn) (1.4.1)\nRequirement already satisfied: cython>=0.29.15 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from sparse_dot_topn) (0.29.23)\nRequirement already satisfied: setuptools>=18.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from sparse_dot_topn) (45.2.0)\nRequirement already satisfied: numpy>=1.16.6 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from sparse_dot_topn) (1.19.5)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "!pip install sparse_dot_topn #uncomment to install\n",
    "import sparse_dot_topn.sparse_dot_topn as ct\n",
    "\n",
    "\n",
    "def awesome_cossim_top(A, B, ntop, lower_bound=0):\n",
    "    # force A and B as a CSR matrix.\n",
    "    # If they have already been CSR, there is no overhead\n",
    "    A = A.tocsr()\n",
    "    B = B.tocsr()\n",
    "    M, _ = A.shape\n",
    "    _, N = B.shape\n",
    " \n",
    "    idx_dtype = np.int32\n",
    " \n",
    "    nnz_max = M*ntop\n",
    " \n",
    "    indptr = np.zeros(M+1, dtype=idx_dtype)\n",
    "    indices = np.zeros(nnz_max, dtype=idx_dtype)\n",
    "    data = np.zeros(nnz_max, dtype=A.dtype)\n",
    "\n",
    "    ct.sparse_dot_topn(\n",
    "        M, N, np.asarray(A.indptr, dtype=idx_dtype),\n",
    "        np.asarray(A.indices, dtype=idx_dtype),\n",
    "        A.data,\n",
    "        np.asarray(B.indptr, dtype=idx_dtype),\n",
    "        np.asarray(B.indices, dtype=idx_dtype),\n",
    "        B.data,\n",
    "        ntop,\n",
    "        lower_bound,\n",
    "        indptr, indices, data)\n",
    "\n",
    "    return csr_matrix((data,indices,indptr),shape=(M,N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "artist_names = df_y[1].dropna().unique()\n",
    "vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams)\n",
    "tf_idf_matrix = vectorizer.fit_transform(artist_names)\n",
    "\n",
    "matches = awesome_cossim_top(tf_idf_matrix, tf_idf_matrix.transpose(), 10, 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matches_df(sparse_matrix, name_vector, top=100):\n",
    "    non_zeros = sparse_matrix.nonzero()\n",
    "    \n",
    "    sparserows = non_zeros[0]\n",
    "    sparsecols = non_zeros[1]\n",
    "    \n",
    "    if top:\n",
    "        nr_matches = top\n",
    "    else:\n",
    "        nr_matches = sparsecols.size\n",
    "    \n",
    "    left_side = np.empty([nr_matches], dtype=object)\n",
    "    right_side = np.empty([nr_matches], dtype=object)\n",
    "    similairity = np.zeros(nr_matches)\n",
    "    \n",
    "    for index in range(0, nr_matches):\n",
    "        left_side[index] = name_vector[sparserows[index]]\n",
    "        right_side[index] = name_vector[sparsecols[index]]\n",
    "        similairity[index] = sparse_matrix.data[index]\n",
    "    \n",
    "    return pd.DataFrame({'left_side': left_side,\n",
    "                          'right_side': right_side,\n",
    "                           'similairity': similairity})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                          left_side                      right_side  \\\n",
       "256                  Christie Craig                    David Clarke   \n",
       "258                    David Clarke                  Christie Craig   \n",
       "875                Elizabeth Swados                  Lecia Cornwall   \n",
       "870                  Lecia Cornwall                Elizabeth Swados   \n",
       "657                  Maria Goldverg                   Andrea Schulz   \n",
       "14                     Faith Hunter                      Rod Duncan   \n",
       "505                     Ally Condie                       Mussolini   \n",
       "507                       Mussolini                     Ally Condie   \n",
       "181                  Chloe Caldwell  Brain Fitness Lab Lisa Mosconi   \n",
       "183  Brain Fitness Lab Lisa Mosconi                  Chloe Caldwell   \n",
       "481                  Carolyn Marino                        Amy Plum   \n",
       "452                   Monica Murphy                     Pura Belpre   \n",
       "455                     Pura Belpre                   Monica Murphy   \n",
       "561                  Kristin Hannah               Jonathan Alderfer   \n",
       "556               Jonathan Alderfer                  Kristin Hannah   \n",
       "15                     Faith Hunter              Matthew De Abaitua   \n",
       "713                 Rebecca Grabill               Roseanne Montillo   \n",
       "715               Roseanne Montillo                 Rebecca Grabill   \n",
       "148                          Ponlop                     Ann Bracken   \n",
       "140                     Ann Bracken                          Ponlop   \n",
       "\n",
       "     similairity  \n",
       "256     0.937906  \n",
       "258     0.937906  \n",
       "875     0.927152  \n",
       "870     0.927152  \n",
       "657     0.920448  \n",
       "14      0.911747  \n",
       "505     0.910818  \n",
       "507     0.910818  \n",
       "181     0.905992  \n",
       "183     0.905992  \n",
       "481     0.905885  \n",
       "452     0.887648  \n",
       "455     0.887648  \n",
       "561     0.886312  \n",
       "556     0.886312  \n",
       "15      0.879666  \n",
       "713     0.879151  \n",
       "715     0.879151  \n",
       "148     0.877893  \n",
       "140     0.877893  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>left_side</th>\n      <th>right_side</th>\n      <th>similairity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>256</th>\n      <td>Christie Craig</td>\n      <td>David Clarke</td>\n      <td>0.937906</td>\n    </tr>\n    <tr>\n      <th>258</th>\n      <td>David Clarke</td>\n      <td>Christie Craig</td>\n      <td>0.937906</td>\n    </tr>\n    <tr>\n      <th>875</th>\n      <td>Elizabeth Swados</td>\n      <td>Lecia Cornwall</td>\n      <td>0.927152</td>\n    </tr>\n    <tr>\n      <th>870</th>\n      <td>Lecia Cornwall</td>\n      <td>Elizabeth Swados</td>\n      <td>0.927152</td>\n    </tr>\n    <tr>\n      <th>657</th>\n      <td>Maria Goldverg</td>\n      <td>Andrea Schulz</td>\n      <td>0.920448</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Faith Hunter</td>\n      <td>Rod Duncan</td>\n      <td>0.911747</td>\n    </tr>\n    <tr>\n      <th>505</th>\n      <td>Ally Condie</td>\n      <td>Mussolini</td>\n      <td>0.910818</td>\n    </tr>\n    <tr>\n      <th>507</th>\n      <td>Mussolini</td>\n      <td>Ally Condie</td>\n      <td>0.910818</td>\n    </tr>\n    <tr>\n      <th>181</th>\n      <td>Chloe Caldwell</td>\n      <td>Brain Fitness Lab Lisa Mosconi</td>\n      <td>0.905992</td>\n    </tr>\n    <tr>\n      <th>183</th>\n      <td>Brain Fitness Lab Lisa Mosconi</td>\n      <td>Chloe Caldwell</td>\n      <td>0.905992</td>\n    </tr>\n    <tr>\n      <th>481</th>\n      <td>Carolyn Marino</td>\n      <td>Amy Plum</td>\n      <td>0.905885</td>\n    </tr>\n    <tr>\n      <th>452</th>\n      <td>Monica Murphy</td>\n      <td>Pura Belpre</td>\n      <td>0.887648</td>\n    </tr>\n    <tr>\n      <th>455</th>\n      <td>Pura Belpre</td>\n      <td>Monica Murphy</td>\n      <td>0.887648</td>\n    </tr>\n    <tr>\n      <th>561</th>\n      <td>Kristin Hannah</td>\n      <td>Jonathan Alderfer</td>\n      <td>0.886312</td>\n    </tr>\n    <tr>\n      <th>556</th>\n      <td>Jonathan Alderfer</td>\n      <td>Kristin Hannah</td>\n      <td>0.886312</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Faith Hunter</td>\n      <td>Matthew De Abaitua</td>\n      <td>0.879666</td>\n    </tr>\n    <tr>\n      <th>713</th>\n      <td>Rebecca Grabill</td>\n      <td>Roseanne Montillo</td>\n      <td>0.879151</td>\n    </tr>\n    <tr>\n      <th>715</th>\n      <td>Roseanne Montillo</td>\n      <td>Rebecca Grabill</td>\n      <td>0.879151</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>Ponlop</td>\n      <td>Ann Bracken</td>\n      <td>0.877893</td>\n    </tr>\n    <tr>\n      <th>140</th>\n      <td>Ann Bracken</td>\n      <td>Ponlop</td>\n      <td>0.877893</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "\n",
    "matches_df = get_matches_df(matches, artist_name, top=1000)\n",
    "matches_df = matches_df[matches_df['similairity'] < 0.99999] # Remove all exact matches\n",
    "matches_df.sample(20)\n",
    "matches_df.sort_values(['similairity'], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Vectorizing the data - this could take a few minutes for large datasets...\n",
      "Vectorizing completed...\n",
      "getting nearest n...\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-16682e43350e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'getting nearest n...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetNearestN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_org\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"COMPLETED IN:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-16682e43350e>\u001b[0m in \u001b[0;36mgetNearestN\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetNearestN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0mqueryTFIDF_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnbrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueryTFIDF_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    638\u001b[0m                 \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m             chunked_results = list(pairwise_distances_chunked(\n\u001b[0m\u001b[1;32m    641\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m                 \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1602\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreduce_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m             \u001b[0mchunk_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1604\u001b[0;31m             \u001b[0mD_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1605\u001b[0m             \u001b[0m_check_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1606\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mD_chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36m_kneighbors_reduce_func\u001b[0;34m(self, dist, start, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    516\u001b[0m         \"\"\"\n\u001b[1;32m    517\u001b[0m         \u001b[0msample_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m         \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneigh_ind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;31m# argpartition doesn't guarantee sorted order, so we sort again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margpartition\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margpartition\u001b[0;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m     \"\"\"\n\u001b[0;32m--> 832\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argpartition'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "artist_name_clean = df_x['author'].dropna().unique()\n",
    "\n",
    "print('Vectorizing the data - this could take a few minutes for large datasets...')\n",
    "vectorizer = TfidfVectorizer(min_df=1, analyzer=ngrams, lowercase=False)\n",
    "tfidf = vectorizer.fit_transform(artist_name_clean)\n",
    "print('Vectorizing completed...')\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "nbrs = NearestNeighbors(n_neighbors=1, n_jobs=-1).fit(tfidf)\n",
    "\n",
    "org_column = 'buyer' #column to match against in the messy data\n",
    "unique_artist = set(df_y['author'].values) # set used for increased performance\n",
    "\n",
    "\n",
    "###matching query:\n",
    "def getNearestN(query):\n",
    "  queryTFIDF_ = vectorizer.transform(query)\n",
    "  distances, indices = nbrs.kneighbors(queryTFIDF_)\n",
    "  return distances, indices\n",
    "\n",
    "import time\n",
    "t1 = time.time()\n",
    "print('getting nearest n...')\n",
    "distances, indices = getNearestN(unique_org)\n",
    "t = time.time()-t1\n",
    "print(\"COMPLETED IN:\", t)\n",
    "\n",
    "unique_org = list(unique_org) #need to convert back to a list\n",
    "print('finding matches...')\n",
    "matches = []\n",
    "for i,j in enumerate(indices):\n",
    "  temp = [round(distances[i][0],2), artist_name_clean.values[j][0][0],unique_artist[i]]\n",
    "  matches.append(temp)\n",
    "\n",
    "print('Building data frame...')  \n",
    "matches = pd.DataFrame(matches, columns=['Match confidence (lower is better)','Matched name','Origional name'])\n",
    "print('Done') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         0                author\n",
       "0        1          Allen Eskens\n",
       "1        2            C.D. Reiss\n",
       "2        3       Catherine Gayle\n",
       "3        4      Daniel J. Siegel\n",
       "4        5       Debbie Macomber\n",
       "...    ...                   ...\n",
       "8297  8298             Zondervan\n",
       "8298  8299    Zora Neale Hurston\n",
       "8299  8300  edited by Brian Kram\n",
       "8300  8301  âConsumer Reportsâ\n",
       "8301  8302    âVibeâ editors\n",
       "\n",
       "[8302 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>author</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Allen Eskens</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>C.D. Reiss</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Catherine Gayle</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Daniel J. Siegel</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Debbie Macomber</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8297</th>\n      <td>8298</td>\n      <td>Zondervan</td>\n    </tr>\n    <tr>\n      <th>8298</th>\n      <td>8299</td>\n      <td>Zora Neale Hurston</td>\n    </tr>\n    <tr>\n      <th>8299</th>\n      <td>8300</td>\n      <td>edited by Brian Kram</td>\n    </tr>\n    <tr>\n      <th>8300</th>\n      <td>8301</td>\n      <td>âConsumer Reportsâ</td>\n    </tr>\n    <tr>\n      <th>8301</th>\n      <td>8302</td>\n      <td>âVibeâ editors</td>\n    </tr>\n  </tbody>\n</table>\n<p>8302 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "df_y = df_y.rename(columns={1: \"author\"})\n",
    "df_y"
   ]
  },
  {
   "source": [
    "# Last try Guillaume\n",
    "* https://towardsdatascience.com/fuzzy-string-match-with-python-on-large-dataset-and-why-you-should-not-use-fuzzywuzzy-4ec9f0defcd"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import gc\n",
    "import timeit\n",
    "import sys\n",
    "from datetime import datetime as dt\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = pd.read_csv('./data/input_x.csv',error_bad_lines=False,encoding='utf-8',sep=\"\\t\").iloc[1:,:]\n",
    "df_y = pd.read_csv('./data/input_y.csv',error_bad_lines=False,encoding='ISO 8859-1',sep=\"\\t\",header=None)\n",
    "\n",
    "df_x = df_x.iloc[:1000,:]\n",
    "df_y = df_y.iloc[:1000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   0                 1\n",
       "0  1      Allen Eskens\n",
       "1  2        C.D. Reiss\n",
       "2  3   Catherine Gayle\n",
       "3  4  Daniel J. Siegel\n",
       "4  5   Debbie Macomber"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Allen Eskens</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>C.D. Reiss</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Catherine Gayle</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Daniel J. Siegel</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Debbie Macomber</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df_y.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_prepare(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: a clean string\n",
    "    \"\"\"\n",
    "    REPLACE_BY_SPACE_RE = re.compile('[\\n\\\"\\'/(){}\\[\\]\\|@,;#]')\n",
    "    text = re.sub(REPLACE_BY_SPACE_RE, ' ', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # delete stopwords from text\n",
    "    text = ' '.join([word for word in text.split()]) \n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "id         int64\n",
       "author    string\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df_x['author'] = df_x['author'].astype('string')\n",
    "df_x.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    0                                  1\n",
       "0   1                       Allen Eskens\n",
       "1   2                         C.D. Reiss\n",
       "2   3                    Catherine Gayle\n",
       "3   4                   Daniel J. Siegel\n",
       "4   5                    Debbie Macomber\n",
       "5   6                        Dick Morris\n",
       "6   7               Dolen Perkins-Valdez\n",
       "7   8               Donna Woolfolk Cross\n",
       "8   9  Douglas Preston and Lincoln Child\n",
       "9  10                       Emily Giffin"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Allen Eskens</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>C.D. Reiss</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Catherine Gayle</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Daniel J. Siegel</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Debbie Macomber</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>Dick Morris</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>Dolen Perkins-Valdez</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>Donna Woolfolk Cross</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>Douglas Preston and Lincoln Child</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>Emily Giffin</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df_y.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df_x.fillna(\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id            author            Author\n",
       "1   1     Charles Sykes     charles sykes\n",
       "2   2        Yogi Berra        yogi berra\n",
       "3   3  Michael Crichton  michael crichton\n",
       "4   4             Hegar             hegar\n",
       "5   5     Ken Bensinger     ken bensinger"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>author</th>\n      <th>Author</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Charles Sykes</td>\n      <td>charles sykes</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Yogi Berra</td>\n      <td>yogi berra</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Michael Crichton</td>\n      <td>michael crichton</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Hegar</td>\n      <td>hegar</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>Ken Bensinger</td>\n      <td>ken bensinger</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df_x['Author'] = df_x['author'].apply(lambda x: text_prepare(x))\n",
    "df_y['author'] = df_y[1].apply(lambda x: text_prepare(x))\n",
    "df_x.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform text to vectors with TF-IDF\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2), max_df=0.9, min_df=5, token_pattern='(\\S+)')\n",
    "tf_idf_matrix_x = tfidf_vectorizer.fit_transform(df_x['Author'])\n",
    "tf_idf_matrix_y = tfidf_vectorizer.fit_transform(df_y['author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: sparse_dot_topn in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (0.2.9)\n",
      "Requirement already satisfied: scipy>=1.2.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from sparse_dot_topn) (1.6.1)\n",
      "Requirement already satisfied: cython>=0.29.15 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from sparse_dot_topn) (0.29.23)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from sparse_dot_topn) (1.19.5)\n",
      "Requirement already satisfied: setuptools>=18.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from sparse_dot_topn) (45.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "finished in: 0.002249002456665039\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "!pip install sparse_dot_topn \n",
    "import sparse_dot_topn.sparse_dot_topn as ct\n",
    "\n",
    "def awesome_cossim_top(A, B, ntop, lower_bound=0):\n",
    "    # force A and B as a CSR matrix.\n",
    "    # If they have already been CSR, there is no overhead\n",
    "    A = A.tocsr()\n",
    "    B = B.tocsr()\n",
    "    M, _ = A.shape\n",
    "    _, N = B.shape\n",
    " \n",
    "    idx_dtype = np.int32\n",
    " \n",
    "    nnz_max = M*ntop\n",
    " \n",
    "    indptr = np.zeros(M+1, dtype=idx_dtype)\n",
    "    indices = np.zeros(nnz_max, dtype=idx_dtype)\n",
    "    data = np.zeros(nnz_max, dtype=A.dtype)\n",
    "    ct.sparse_dot_topn(\n",
    "            M, N, np.asarray(A.indptr, dtype=idx_dtype),\n",
    "            np.asarray(A.indices, dtype=idx_dtype),\n",
    "            A.data,\n",
    "            np.asarray(B.indptr, dtype=idx_dtype),\n",
    "            np.asarray(B.indices, dtype=idx_dtype),\n",
    "            B.data,\n",
    "            ntop,\n",
    "            lower_bound,\n",
    "            indptr, indices, data)\n",
    "    return csr_matrix((data,indices,indptr),shape=(M,N))\n",
    "\n",
    "\n",
    "import time\n",
    "t1 = time.time()\n",
    "\n",
    "# adjust lower bound: 0.8\n",
    "# keep top 10 similar results\n",
    "matches = awesome_cossim_top(tf_idf_matrix_x, tf_idf_matrix_y.transpose(), 10, 0.8)\n",
    "\n",
    "t = time.time()-t1\n",
    "print(\"finished in:\", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'Author'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/MyProjects/JobProjects/Data science Peukert/Fuzzymatching/Fuzzymatch/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Author'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-a74545ec7ea4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mmatches_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mmatches_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_matches_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Author'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;31m# Remove all exact matches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mmatches_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatches_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmatches_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'similairity_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.99999\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MyProjects/JobProjects/Data science Peukert/Fuzzymatching/Fuzzymatch/venv/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MyProjects/JobProjects/Data science Peukert/Fuzzymatching/Fuzzymatch/venv/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Author'"
     ]
    }
   ],
   "source": [
    "def get_matches_df(sparse_matrix, name_vector, top=100):\n",
    "    non_zeros = sparse_matrix.nonzero()\n",
    "    \n",
    "    sparserows = non_zeros[0]\n",
    "    sparsecols = non_zeros[1]\n",
    "    \n",
    "    if top:\n",
    "        nr_matches = top\n",
    "    else:\n",
    "        nr_matches = sparsecols.size\n",
    "    \n",
    "    left_side = np.empty([nr_matches], dtype=object)\n",
    "    right_side = np.empty([nr_matches], dtype=object)\n",
    "    similairity = np.zeros(nr_matches)\n",
    "    \n",
    "    for index in range(0, nr_matches):\n",
    "        left_side[index] = name_vector[sparserows[index]]\n",
    "        right_side[index] = name_vector[sparsecols[index]]\n",
    "        similairity[index] = sparse_matrix.data[index]\n",
    "    \n",
    "    return pd.DataFrame({'TITLE': left_side,\n",
    "                          'SIMILAR_TITLE': right_side,\n",
    "                           'similairity_score': similairity})\n",
    "  \n",
    "  \n",
    "  \n",
    "matches_df = pd.DataFrame()\n",
    "matches_df = get_matches_df(matches, df_x['Author'], top=10000)\n",
    "# Remove all exact matches\n",
    "matches_df = matches_df[matches_df['similairity_score'] < 0.99999] \n",
    "matches_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                     TITLE            SIMILAR_TITLE  \\\n",
       "9708                         nebula awards     nebula awards awards   \n",
       "3658    arthur ellis unhanged arthur award       arthur ellis award   \n",
       "3657    arthur ellis unhanged arthur award       arthur ellis award   \n",
       "3656    arthur ellis unhanged arthur award       arthur ellis award   \n",
       "7281                            nino ricci         award nino ricci   \n",
       "1949                     charlotte zolotow  charlotte zolotow award   \n",
       "8574                         tom o donnell       sunshine o donnell   \n",
       "9507  wallace stegner fellow abigail ulman   wallace stegner fellow   \n",
       "9508  wallace stegner fellow abigail ulman   wallace stegner fellow   \n",
       "9509  wallace stegner fellow abigail ulman   wallace stegner fellow   \n",
       "4556                 arthur ellis unhanged       arthur ellis award   \n",
       "4555                 arthur ellis unhanged       arthur ellis award   \n",
       "4554                 arthur ellis unhanged       arthur ellis award   \n",
       "1179                       george o connor          varley o connor   \n",
       "1178                       george o connor          varley o connor   \n",
       "1177                       george o connor              tj o connor   \n",
       "1176                       george o connor         malachi o connor   \n",
       "4358                          david shafer                   shafer   \n",
       "7379                     chantele sedgwick            john sedgwick   \n",
       "448                               john all        against all grain   \n",
       "\n",
       "      similairity_score  \n",
       "9708           0.952539  \n",
       "3658           0.947048  \n",
       "3657           0.947048  \n",
       "3656           0.947048  \n",
       "7281           0.944778  \n",
       "1949           0.933302  \n",
       "8574           0.921246  \n",
       "9507           0.919925  \n",
       "9508           0.919925  \n",
       "9509           0.919925  \n",
       "4556           0.918731  \n",
       "4555           0.918731  \n",
       "4554           0.918731  \n",
       "1179           0.904928  \n",
       "1178           0.904928  \n",
       "1177           0.904928  \n",
       "1176           0.904928  \n",
       "4358           0.904260  \n",
       "7379           0.902625  \n",
       "448            0.902625  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TITLE</th>\n      <th>SIMILAR_TITLE</th>\n      <th>similairity_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9708</th>\n      <td>nebula awards</td>\n      <td>nebula awards awards</td>\n      <td>0.952539</td>\n    </tr>\n    <tr>\n      <th>3658</th>\n      <td>arthur ellis unhanged arthur award</td>\n      <td>arthur ellis award</td>\n      <td>0.947048</td>\n    </tr>\n    <tr>\n      <th>3657</th>\n      <td>arthur ellis unhanged arthur award</td>\n      <td>arthur ellis award</td>\n      <td>0.947048</td>\n    </tr>\n    <tr>\n      <th>3656</th>\n      <td>arthur ellis unhanged arthur award</td>\n      <td>arthur ellis award</td>\n      <td>0.947048</td>\n    </tr>\n    <tr>\n      <th>7281</th>\n      <td>nino ricci</td>\n      <td>award nino ricci</td>\n      <td>0.944778</td>\n    </tr>\n    <tr>\n      <th>1949</th>\n      <td>charlotte zolotow</td>\n      <td>charlotte zolotow award</td>\n      <td>0.933302</td>\n    </tr>\n    <tr>\n      <th>8574</th>\n      <td>tom o donnell</td>\n      <td>sunshine o donnell</td>\n      <td>0.921246</td>\n    </tr>\n    <tr>\n      <th>9507</th>\n      <td>wallace stegner fellow abigail ulman</td>\n      <td>wallace stegner fellow</td>\n      <td>0.919925</td>\n    </tr>\n    <tr>\n      <th>9508</th>\n      <td>wallace stegner fellow abigail ulman</td>\n      <td>wallace stegner fellow</td>\n      <td>0.919925</td>\n    </tr>\n    <tr>\n      <th>9509</th>\n      <td>wallace stegner fellow abigail ulman</td>\n      <td>wallace stegner fellow</td>\n      <td>0.919925</td>\n    </tr>\n    <tr>\n      <th>4556</th>\n      <td>arthur ellis unhanged</td>\n      <td>arthur ellis award</td>\n      <td>0.918731</td>\n    </tr>\n    <tr>\n      <th>4555</th>\n      <td>arthur ellis unhanged</td>\n      <td>arthur ellis award</td>\n      <td>0.918731</td>\n    </tr>\n    <tr>\n      <th>4554</th>\n      <td>arthur ellis unhanged</td>\n      <td>arthur ellis award</td>\n      <td>0.918731</td>\n    </tr>\n    <tr>\n      <th>1179</th>\n      <td>george o connor</td>\n      <td>varley o connor</td>\n      <td>0.904928</td>\n    </tr>\n    <tr>\n      <th>1178</th>\n      <td>george o connor</td>\n      <td>varley o connor</td>\n      <td>0.904928</td>\n    </tr>\n    <tr>\n      <th>1177</th>\n      <td>george o connor</td>\n      <td>tj o connor</td>\n      <td>0.904928</td>\n    </tr>\n    <tr>\n      <th>1176</th>\n      <td>george o connor</td>\n      <td>malachi o connor</td>\n      <td>0.904928</td>\n    </tr>\n    <tr>\n      <th>4358</th>\n      <td>david shafer</td>\n      <td>shafer</td>\n      <td>0.904260</td>\n    </tr>\n    <tr>\n      <th>7379</th>\n      <td>chantele sedgwick</td>\n      <td>john sedgwick</td>\n      <td>0.902625</td>\n    </tr>\n    <tr>\n      <th>448</th>\n      <td>john all</td>\n      <td>against all grain</td>\n      <td>0.902625</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "matches_df.sort_values([\"similairity_score\"], ascending=False).head(20)"
   ]
  },
  {
   "source": [
    "### tester cette méthode: https://github.com/Christopher-Thornton/hmni\n",
    "* Deezy match (https://github.com/Living-with-machines/DeezyMatch)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test avec append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             author\n",
       "0     charles sykes\n",
       "1        yogi berra\n",
       "2  michael crichton\n",
       "3             hegar\n",
       "4     ken bensinger"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>author</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>charles sykes</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>yogi berra</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>michael crichton</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>hegar</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ken bensinger</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import fuzzy_pandas as fpd\n",
    "import re\n",
    "def text_prepare(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: a clean string\n",
    "    \"\"\"\n",
    "    REPLACE_BY_SPACE_RE = re.compile('[\\n\\\"\\'/(){}\\[\\]\\|@,;#]')\n",
    "    text = re.sub(REPLACE_BY_SPACE_RE, ' ', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # delete stopwords from text\n",
    "    text = ' '.join([word for word in text.split()]) \n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "df_x = pd.read_csv('./data/input_x.csv',error_bad_lines=False,encoding='utf-8',sep=\"\\t\").iloc[1:,:]\n",
    "df_y = pd.read_csv('./data/input_y.csv',error_bad_lines=False,encoding='ISO 8859-1',sep=\"\\t\",header=None)\n",
    "\n",
    "df_x['author'] = df_x['author'].astype('string')\n",
    "df_y['author'] = df_y[1].astype('string')\n",
    "\n",
    "del df_x['id']\n",
    "del df_y[0]\n",
    "del df_y[1]\n",
    "\n",
    "\n",
    "df_merge = df_x.append(df_y, ignore_index=True)\n",
    "df_merge = df_merge.dropna()\n",
    "df_merge['author'] = df_merge['author'].apply(lambda x: text_prepare(x))\n",
    "df_merge.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform text to vectors with TF-IDF\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2), max_df=0.9, min_df=5, token_pattern='(\\S+)')\n",
    "tf_idf_matrix = tfidf_vectorizer.fit_transform(df_merge['author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "finished in: 0.6329741477966309\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import sparse_dot_topn.sparse_dot_topn as ct\n",
    "import numpy as np\n",
    "\n",
    "def awesome_cossim_top(A, B, ntop, lower_bound=0):\n",
    "    # force A and B as a CSR matrix.\n",
    "    # If they have already been CSR, there is no overhead\n",
    "    A = A.tocsr()\n",
    "    B = B.tocsr()\n",
    "    M, _ = A.shape\n",
    "    _, N = B.shape\n",
    " \n",
    "    idx_dtype = np.int32\n",
    " \n",
    "    nnz_max = M*ntop\n",
    " \n",
    "    indptr = np.zeros(M+1, dtype=idx_dtype)\n",
    "    indices = np.zeros(nnz_max, dtype=idx_dtype)\n",
    "    data = np.zeros(nnz_max, dtype=A.dtype)\n",
    "    ct.sparse_dot_topn(\n",
    "            M, N, np.asarray(A.indptr, dtype=idx_dtype),\n",
    "            np.asarray(A.indices, dtype=idx_dtype),\n",
    "            A.data,\n",
    "            np.asarray(B.indptr, dtype=idx_dtype),\n",
    "            np.asarray(B.indices, dtype=idx_dtype),\n",
    "            B.data,\n",
    "            ntop,\n",
    "            lower_bound,\n",
    "            indptr, indices, data)\n",
    "    return csr_matrix((data,indices,indptr),shape=(M,N))\n",
    "\n",
    "\n",
    "import time\n",
    "t1 = time.time()\n",
    "\n",
    "# adjust lower bound: 0.8\n",
    "# keep top 10 similar results\n",
    "matches = awesome_cossim_top(tf_idf_matrix, tf_idf_matrix.transpose(), 10, 0.8)\n",
    "\n",
    "t = time.time()-t1\n",
    "print(\"finished in:\", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10000\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  TITLE                 SIMILAR_TITLE  similairity_score\n",
       "2733         marta elva                 leslie cerier           0.840170\n",
       "7694         gill lewis                   anita albus           0.816033\n",
       "6146          yaa gyasi  guinness world records staff           0.839506\n",
       "4795          joya ryan                stephen walker           0.819333\n",
       "4537  richard moskovitz                 isabel losada           0.917485\n",
       "461    geraldine brooks                  jodi daynard           0.838510\n",
       "5840  chris struyk-bonn                       jeffrey           0.803970\n",
       "2832   brandi dougherty               robert mcgovern           0.826604\n",
       "8162     michael harvey                  karyn marcus           0.854737\n",
       "170         john harvey                         stead           0.845525"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TITLE</th>\n      <th>SIMILAR_TITLE</th>\n      <th>similairity_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2733</th>\n      <td>marta elva</td>\n      <td>leslie cerier</td>\n      <td>0.840170</td>\n    </tr>\n    <tr>\n      <th>7694</th>\n      <td>gill lewis</td>\n      <td>anita albus</td>\n      <td>0.816033</td>\n    </tr>\n    <tr>\n      <th>6146</th>\n      <td>yaa gyasi</td>\n      <td>guinness world records staff</td>\n      <td>0.839506</td>\n    </tr>\n    <tr>\n      <th>4795</th>\n      <td>joya ryan</td>\n      <td>stephen walker</td>\n      <td>0.819333</td>\n    </tr>\n    <tr>\n      <th>4537</th>\n      <td>richard moskovitz</td>\n      <td>isabel losada</td>\n      <td>0.917485</td>\n    </tr>\n    <tr>\n      <th>461</th>\n      <td>geraldine brooks</td>\n      <td>jodi daynard</td>\n      <td>0.838510</td>\n    </tr>\n    <tr>\n      <th>5840</th>\n      <td>chris struyk-bonn</td>\n      <td>jeffrey</td>\n      <td>0.803970</td>\n    </tr>\n    <tr>\n      <th>2832</th>\n      <td>brandi dougherty</td>\n      <td>robert mcgovern</td>\n      <td>0.826604</td>\n    </tr>\n    <tr>\n      <th>8162</th>\n      <td>michael harvey</td>\n      <td>karyn marcus</td>\n      <td>0.854737</td>\n    </tr>\n    <tr>\n      <th>170</th>\n      <td>john harvey</td>\n      <td>stead</td>\n      <td>0.845525</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "def get_matches_df(sparse_matrix, name_vector, top=100):\n",
    "    non_zeros = sparse_matrix.nonzero()\n",
    "    \n",
    "    sparserows = non_zeros[0]\n",
    "    sparsecols = non_zeros[1]\n",
    "    \n",
    "    if top:\n",
    "        nr_matches = top\n",
    "    else:\n",
    "        nr_matches = sparsecols.size\n",
    "    \n",
    "    print(nr_matches)\n",
    "    left_side = np.empty([nr_matches], dtype=object)\n",
    "    right_side = np.empty([nr_matches], dtype=object)\n",
    "    similairity = np.zeros(nr_matches)\n",
    "    \n",
    "    for index in range(0, nr_matches):\n",
    "        #print(index)\n",
    "        try:\n",
    "            left_side[index] = name_vector[sparserows[index]]\n",
    "            right_side[index] = name_vector[sparsecols[index]]\n",
    "            similairity[index] = sparse_matrix.data[index]\n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame({'TITLE': left_side,\n",
    "                          'SIMILAR_TITLE': right_side,\n",
    "                           'similairity_score': similairity})\n",
    "  \n",
    "  \n",
    "  \n",
    "matches_df = pd.DataFrame()\n",
    "matches_df = get_matches_df(matches, df_merge['author'], top=10000)\n",
    "# Remove all exact matches\n",
    "matches_df = matches_df[matches_df['similairity_score'] < 0.99999] \n",
    "matches_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(686, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "matches_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  TITLE              SIMILAR_TITLE  similairity_score\n",
       "9735       megan abbott              liza donnelly           0.952504\n",
       "6285   kelley armstrong                anita mills           0.951120\n",
       "6686       peter straub                anita mills           0.951120\n",
       "3642            history              isabel losada           0.947379\n",
       "3643            history              liza marklund           0.947379\n",
       "3644            history  paulette kouffman sherman           0.947379\n",
       "7268            twitter                 john wasik           0.943470\n",
       "1930        skila brown             james altucher           0.932588\n",
       "8452             daniel          max allan collins           0.926822\n",
       "8594         mindy meja                david lynch           0.922086\n",
       "9534        tom michell           arthur rosenfeld           0.919662\n",
       "9536        tom michell               ashley mills           0.919662\n",
       "9535        tom michell                jim butcher           0.919662\n",
       "4539  richard moskovitz  paulette kouffman sherman           0.917485\n",
       "4538  richard moskovitz              liza marklund           0.917485\n",
       "4537  richard moskovitz              isabel losada           0.917485\n",
       "1171        jason eaton             cheryl diamond           0.905961\n",
       "1169        jason eaton               gordon weiss           0.905961\n",
       "1170        jason eaton                james burks           0.905961\n",
       "4342            doritos         annette economides           0.905548"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TITLE</th>\n      <th>SIMILAR_TITLE</th>\n      <th>similairity_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9735</th>\n      <td>megan abbott</td>\n      <td>liza donnelly</td>\n      <td>0.952504</td>\n    </tr>\n    <tr>\n      <th>6285</th>\n      <td>kelley armstrong</td>\n      <td>anita mills</td>\n      <td>0.951120</td>\n    </tr>\n    <tr>\n      <th>6686</th>\n      <td>peter straub</td>\n      <td>anita mills</td>\n      <td>0.951120</td>\n    </tr>\n    <tr>\n      <th>3642</th>\n      <td>history</td>\n      <td>isabel losada</td>\n      <td>0.947379</td>\n    </tr>\n    <tr>\n      <th>3643</th>\n      <td>history</td>\n      <td>liza marklund</td>\n      <td>0.947379</td>\n    </tr>\n    <tr>\n      <th>3644</th>\n      <td>history</td>\n      <td>paulette kouffman sherman</td>\n      <td>0.947379</td>\n    </tr>\n    <tr>\n      <th>7268</th>\n      <td>twitter</td>\n      <td>john wasik</td>\n      <td>0.943470</td>\n    </tr>\n    <tr>\n      <th>1930</th>\n      <td>skila brown</td>\n      <td>james altucher</td>\n      <td>0.932588</td>\n    </tr>\n    <tr>\n      <th>8452</th>\n      <td>daniel</td>\n      <td>max allan collins</td>\n      <td>0.926822</td>\n    </tr>\n    <tr>\n      <th>8594</th>\n      <td>mindy meja</td>\n      <td>david lynch</td>\n      <td>0.922086</td>\n    </tr>\n    <tr>\n      <th>9534</th>\n      <td>tom michell</td>\n      <td>arthur rosenfeld</td>\n      <td>0.919662</td>\n    </tr>\n    <tr>\n      <th>9536</th>\n      <td>tom michell</td>\n      <td>ashley mills</td>\n      <td>0.919662</td>\n    </tr>\n    <tr>\n      <th>9535</th>\n      <td>tom michell</td>\n      <td>jim butcher</td>\n      <td>0.919662</td>\n    </tr>\n    <tr>\n      <th>4539</th>\n      <td>richard moskovitz</td>\n      <td>paulette kouffman sherman</td>\n      <td>0.917485</td>\n    </tr>\n    <tr>\n      <th>4538</th>\n      <td>richard moskovitz</td>\n      <td>liza marklund</td>\n      <td>0.917485</td>\n    </tr>\n    <tr>\n      <th>4537</th>\n      <td>richard moskovitz</td>\n      <td>isabel losada</td>\n      <td>0.917485</td>\n    </tr>\n    <tr>\n      <th>1171</th>\n      <td>jason eaton</td>\n      <td>cheryl diamond</td>\n      <td>0.905961</td>\n    </tr>\n    <tr>\n      <th>1169</th>\n      <td>jason eaton</td>\n      <td>gordon weiss</td>\n      <td>0.905961</td>\n    </tr>\n    <tr>\n      <th>1170</th>\n      <td>jason eaton</td>\n      <td>james burks</td>\n      <td>0.905961</td>\n    </tr>\n    <tr>\n      <th>4342</th>\n      <td>doritos</td>\n      <td>annette economides</td>\n      <td>0.905548</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "matches_df.sort_values([\"similairity_score\"], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}